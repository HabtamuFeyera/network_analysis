{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "# import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path to import modules from src\n",
    "rpath = os.path.abspath('..')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)\n",
    "\n",
    "from src.loader import SlackDataLoader\n",
    "from src.preprocessing import Preprocessing\n",
    "# Initialize DataLoader\n",
    "sl = SlackDataLoader('../Anonymized_B6SlackExport_25Nov23/anonymized/')\n",
    "# converting all json files for all-community-building channel to dataframe using slack_parser method from loader script\n",
    "df_community = sl.slack_parser('../Anonymized_B6SlackExport_25Nov23/anonymized/all-community-building/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'message_sent_time' to datetime format\n",
    "# df['message_sent_time'] = pd.to_datetime(df['message_sent_time'])\n",
    "df_community['msg_sent_time'] = pd.to_datetime(df_community['msg_sent_time'], unit='s')\n",
    "\n",
    "# Sort the DataFrame by 'message_sent_time'\n",
    "df_community = df_community.sort_values(by='msg_sent_time')\n",
    "\n",
    "# Calculate time differences between consecutive messages\n",
    "df_community['time_difference'] = df_community['msg_sent_time'].diff()\n",
    "\n",
    "# Plot the distribution of time differences\n",
    "plt.hist(df_community['time_difference'].dt.total_seconds(), bins=50, edgecolor='black')\n",
    "plt.xlabel('Time Differences (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Time Differences Between Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the maximum reply_count\n",
    "max_reply_count= df_community['reply_count'].max()\n",
    "max_reply_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_content = sl.get_channel_messages(channel_name='all-community-building')\n",
    "def filter_msg(msg_content):\n",
    "    \n",
    "    for msg in msg_content:\n",
    "        if 'reply_count' in msg.keys():\n",
    "            if msg['reply_count']==75:\n",
    "                return msg\n",
    "top_reply_count_message = filter_msg(msg_content)\n",
    "# convery replies key to a dataframe\n",
    "df_replies = pd.DataFrame(top_reply_count_message['replies'])\n",
    "df_replies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies['ts'] = pd.to_datetime(df_replies['ts'], unit='s')\n",
    "\n",
    "# Sort the DataFrame by 'message_sent_time'\n",
    "df_replies = df_replies.sort_values(by='ts')\n",
    "\n",
    "# Calculate time differences between consecutive messages\n",
    "df_replies['time_difference'] = df_replies['ts'].diff()\n",
    "\n",
    "# Plot the distribution of time differences\n",
    "plt.hist(df_replies['time_difference'].dt.total_seconds(), bins=50, edgecolor='black')\n",
    "plt.xlabel('Time Differences (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Time Differences Between Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "from gensim.utils import SaveLoad\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from re import sub\n",
    "import pyLDAvis\n",
    "from collections import Counter\n",
    "from gensim.matutils import corpus2csc, sparse2full, corpus2dense\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.utils import resample\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df_community.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessing(df_community)\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# clean text \n",
    "df_community = preprocess.cleantext('msg_content', 'clean_msg_content')\n",
    "\n",
    "# Stem words\n",
    "df_community = preprocess.stem('clean_msg_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used stemmer instead of lemmatizer\n",
    "cleanKagslacklist = preprocess.filterSlackList(df_community['clean_msg_content'])\n",
    "cleanKagslacklist[1]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
